## 1 GitHub link
[https://github.com/ageron/handson-ml](https://github.com/ageron/handson-ml)
## 2 什么是机器学习？
机器学习是一门能够让编程计算机从数据中学习的计算机科学。
系统用来学习的示例，我们成为训练集
## 3 为什么要机器学习？
- 对于哪些传统根本无法解决的复杂问题，通过好的机器学习技术可以找到一个解决方案
- 对于现有解决方案需要大量手动调整或者是规则列表超长的问题，通过机器学习的算法可以简化代码并提升执行表现
- 对于环境波动：机器学习系统可以适应新的数据
- 从复杂问题和海量数据中获得洞见
## 4 机器学习系统的种类
- 是否在人类监督下训练（监督学习，无监督学习，半监督学习，强化学习）
- 是否可以动态的增量学习（在线学习和批量学习）
- 基于示例的学习和基于模型的学习

### 4.1 监督学习/无监督学习
根据训练期间接受的监督数量和监督的类型，可以将机器学习系统分为以下四个主要类别：监督式学习，无监督式学习，半监督式学习，强化学习
#### 4.1.1 监督式学习
在监督学习中，提供给算法的包含所需要解决方案的训练数据，成为标签或者标记。
- 分类任务是一个典型的监督式学习任务，例如垃圾邮件过滤：通过大量的电子邮件示例以及所属的类别进行训练，然后学习如何对新邮件进行分类。
- 还有一个典型的任务，是通过预测变量，也就是一组给定的特征来预测一个目标值。这类任务成为回归任务。

一些回归算法也可以用于分类任务，反正依然成立。（逻辑回归就被广泛的用于分类）
这里是一些最重要的监督学习算法：

- K-近邻算法
- 线性回归
- 逻辑回归
- 支持向量机
- 决策树和随机森林
- 神经网络

#### 4.1.2 无监督式学习
无监督式学习的训练数据都是未标记的，系统会在没有老师的情况下进行学习。
重要的无监督学习算法：

##### 聚类算法
- K-平均算法
- 分层聚类算法
- 最大期望算法

##### 可视化和降维
- 主成分分析（PCA）
- 核成分分析(Kernal PCA)
- 局部线性嵌入（LLE）
- t-分布随机近邻嵌入（t-SNE）

##### 关联规则学习
- Apriori
- Eclat

无监督学习的例子：
可视化算法，聚类算法检测相似访客的分组。异常检测以及关联规则学习（为了挖掘大量数据，发掘属相之间的联系）
降维:降维的目的是为了在不丢失太多信息的前提下简化数据。
方法之一是将多个相关的特征值合并为一个，这个过程叫做特征值提取。
>推荐做法：先使用降维算法减少训练集数据的维度，再将其供给给机器学习算法（例如监督式学习算法），这样运行的快，占的磁盘空间和内存会更小。性能也更好。

#### 4.1.3 半监督式学习
有些算法可以处理部分标记的训练数据-通常是大量未标记数据和少量标记数据。这称为半监督式学习
例子：相片托管服务（如Google相册）
大多数的半监督式学习算法是无监督学习和监督学习的结合
#### 4.1.4 强化学习
强化学习的系统能够观察环境，做出选择，执行操作，并获得回报。
#### 4.1.5 批量学习和在线学习
- 在批量学习中，系统无法进行增量学习，必须使用所有可用数据进行训练，这需要大量的时间和资源，所有一般情况下都是离线完成的。
离线学习就是先训练系统，然后将其投入到生产环境中，这时学习过程就停止，他只是将所学的应用出来。
- 在在线学习中，你可以循环渐进地给系统提供训练数据，逐步积累学习成果，这种提供数据的方式可以是单独的，也可以采用小批量的数据进行训练。
对于超大数据集，在线学习也同样使用，算法只是每次加载部分数据，并针对部分数据进行训练，然后不断重复整个过程，直到所有数据训练。
    - 在线学习系统还有一个重要参数：它适应不断变化的数据速度。这个是所谓的学习率。
    - 在线学习还有一个重大的挑战：如果给系统输入不良的数据。系统的性能就会下降。
>注意：在线学习通常也是离线完成的（并不是在live的系统上），因此在线学习这个容易让人误解，我们可以视其为增量学习。

#### 4.1.6 基于实例和基于模型的学习
泛化的主要方法有两种：基于实例的学习和基于模型的学习
- 基于实例的学习：系统先完全记住学习示例，然后通过某种相似度度量方式将其泛化到新的示例。
- 基于模型的学习：构建这些示例的模型，然后使用该模型进行预测。这就是基于模型的学习。

## 机器学习的主要挑战
- 训练数据的数量不足
- 训练数据不具有代表性
- 质量差的数据
- 无关特征，特征过程包括：
    - 只有训练数据里包括足够多的相关特征以及较少的无关特征，系统才能够完成学习。
    - 特征选择：从现有特征中选择最有用的特征进行训练
    - 特征提取：将现有特征进行整合，产生更有用的特征
    - 通过收集新数据创造新特征
- 训练数据过度拟合
    - 过度拟合是指模型在训练数据上表现良好，但泛化时却不尽如人意。
- 训练数据拟合不足
    - 拟合不足和过度拟合正好相反，它的产生通常是因为对于下层数据结构来说，你的模型太过简单。
## 测试和验证
将你的数据分为两部分：训练集和测试集，用训练集的数据训练模型，然后用测试集的数据来测试模型。
>通常80%的数据进行训练，20%的数据拿来测试。

    April 27, 2019 pdLibrary sat